{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3409c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DOWNLOAD STOCK DATA\n",
    "import pandas as pd\n",
    "\n",
    "sp500_symbols = pd.read_csv('https://datahub.io/core/s-and-p-500-companies/r/constituents.csv')['Symbol']\n",
    "\n",
    "stock_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "sector_info = {}\n",
    "\n",
    "for symbol in sp500_symbols:\n",
    "    try:\n",
    "        stock = yf.download(symbol, period=\"5y\")\n",
    "        \n",
    "        if symbol not in sector_info:\n",
    "            stock_info = yf.Ticker(symbol).info\n",
    "            sector = stock_info.get(\"sector\", \"N/A\")\n",
    "            sector_info[symbol] = sector\n",
    "        \n",
    "        stock['Symbol'] = symbol\n",
    "        stock['Sector'] = sector_info[symbol]\n",
    "        \n",
    "        stock_data = pd.concat([stock_data, stock])\n",
    "    except Exception as e:\n",
    "        print(f\"Error {symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab915e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.to_csv('stock_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63187f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data= stock_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ec09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling = stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data[stock_data['Symbol'] == 'AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09721b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting tech stocks over a 2 year period \n",
    "import plotly.express as px\n",
    "\n",
    "tech_stocks = ['AAPL','GOOGL','MSFT']\n",
    "\n",
    "for tech in tech_stocks:\n",
    "    \n",
    "    df = stock_data[stock_data['Symbol'] == tech]\n",
    "\n",
    "    fig = px.line(df, x=\"Date\", y='Adj Close', title=tech,\n",
    "                  labels={'Adj Close': 'Stock Price (USD)'}, template='plotly_dark')\n",
    "\n",
    "    fig.update_xaxes(title_text='Date')\n",
    "    fig.update_yaxes(title_text='Stock Price (USD)')\n",
    "    fig.update_layout(showlegend=True)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cfcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting some real estate stocks over 2 year period \n",
    "restate_stocks = ['PLD','AMT','EQIX']\n",
    "\n",
    "for r in restate_stocks:\n",
    "    \n",
    "    df = stock_data[stock_data['Symbol'] == r]\n",
    "\n",
    "    fig = px.line(df, x=\"Date\", y='Adj Close', title=r,\n",
    "                  labels={'Adj Close': 'Stock Price (USD)'}, template='plotly_dark')\n",
    "\n",
    "    fig.update_xaxes(title_text='Date')\n",
    "    fig.update_yaxes(title_text='Stock Price (USD)')\n",
    "    fig.update_layout(showlegend=True)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ff76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data['Daily_Return'] = stock_data['Close'].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866501d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_window = 5  \n",
    "long_window = 20  \n",
    "\n",
    "stock_data['Short_MA'] = stock_data['Close'].rolling(window=short_window).mean()\n",
    "stock_data['Long_MA'] = stock_data['Close'].rolling(window=long_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e45c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#EDA of moving avg \n",
    "df = stock_data\n",
    "\n",
    "tech_stocks = ['AAPL','GOOGL','MSFT']\n",
    "\n",
    "for tech in tech_stocks:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df[df['Symbol']==tech]['Date'], df[df['Symbol']==tech]['Close'], label='Close Price', color='blue', alpha=0.7)\n",
    "    plt.plot(df[df['Symbol']==tech]['Date'], df[df['Symbol']==tech]['Short_MA'], label=f'Short_Moving_Avg ({short_window} days)', color='orange')\n",
    "    plt.plot(df[df['Symbol']==tech]['Date'], df[df['Symbol']==tech]['Long_MA'], label=f'Long_Moving_avg ({long_window} days)', color='green')\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title('Stock Price with Short-term and Long-term Moving Averages')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2c55c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#to understand the hypothesis i wanted to look at the correlation between the percent change between the different sectors \n",
    "#i would assume that families from different sectors would have a correlation of daily pct change \n",
    "\n",
    "import seaborn as sns\n",
    "sp500_sectors = [\n",
    "    'XLC', 'XLY', 'XLC', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLU',\n",
    "    'XPH', 'XME', 'XES', 'XOP', 'XRT', 'XHB', 'XSD', 'XLRE', 'XLRE', 'XLRE'\n",
    "]\n",
    "\n",
    "sector_data = {}\n",
    "for sector in sp500_sectors:\n",
    "    stock = yf.download(sector, period=\"2y\")\n",
    "    sector_data[sector] = stock['Adj Close']\n",
    "\n",
    "returns_df = pd.DataFrame({sector: data.pct_change() for sector, data in sector_data.items()})\n",
    "\n",
    "correlation_matrix = returns_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of S&P 500 Sectors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data = stock_data\n",
    "sp500_data.set_index('Date', inplace=True)\n",
    "def label_monthly(data):\n",
    "    #this is my labeling method\n",
    "    #if the price of the current month is higher than 10% compared to the pervious month this is a price shock\n",
    "    #if the price of the current month is higher than 2% compared to the pervious month this is a Up stock\n",
    "    #if its lower than -2% its a down\n",
    "    #other its a flat\n",
    "    if len(data) < 2:\n",
    "        return pd.Series({'Monthly_Label': 'N/A', 'Close': data['Close'].iloc[-1]})  # Label as 'N/A' and include the last 'Close' value\n",
    "\n",
    "    first_close = data['Close'].iloc[0]\n",
    "    last_close = data['Close'].iloc[-1]\n",
    "\n",
    "    price_change_percent = ((last_close - first_close) / first_close) * 100\n",
    "\n",
    "    if price_change_percent > 10:\n",
    "        return pd.Series({'Monthly_Label': 'Price Shock', 'Close': last_close})\n",
    "    elif price_change_percent < -2:\n",
    "        return pd.Series({'Monthly_Label': 'Down', 'Close': last_close})\n",
    "    elif price_change_percent > 2:\n",
    "        return pd.Series({'Monthly_Label': 'Up', 'Close': last_close})\n",
    "    else:\n",
    "        return pd.Series({'Monthly_Label': 'Flat', 'Close': last_close})\n",
    "\n",
    "labels_df = sp500_data.groupby('Symbol').resample('M').apply(lambda x: label_monthly(x)).reset_index()\n",
    "\n",
    "print(labels_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe762820",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_stock_price_categories(df, tech_stock):\n",
    "    #graphing the nuances in the 2 year period\n",
    "    df = df[df['Symbol'] == tech_stock]\n",
    "    grouped = df.groupby('Monthly_Label')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    colors = {'Flat': 'gray', 'Down': 'red', 'Up': 'green', 'Price Shock': 'blue'}\n",
    "\n",
    "    for label, group in grouped:\n",
    "        ax.scatter(group['Date'], group['Close'], label=label, color=colors[label], alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.title(f'{tech_stock} Stock Price Categories')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "tech_stocks = ['AAPL', 'MSFT', 'GOOGL','NVDA']\n",
    "\n",
    "for tech_stock in tech_stocks:\n",
    "    plot_stock_price_categories(labels_df, tech_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_df.Monthly_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_data = stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa83543",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 730\n",
    "\n",
    "df_stock_data['First_Close'] = df_stock_data.groupby('Symbol')['Close'].transform('first')\n",
    "df_stock_data['Last_Close'] = df_stock_data.groupby('Symbol')['Close'].transform('last')\n",
    "\n",
    "def label_stock(group):\n",
    "    #labeling the stock over a 2 year period\n",
    "    #if its up 5% in 2 years its up\n",
    "    #if its down 5% its down\n",
    "    # other its flat\n",
    "    first_close = group['First_Close'].iloc[0]\n",
    "    last_close = group['Last_Close'].iloc[0]\n",
    "    \n",
    "    percent_diff = (last_close - first_close) / first_close * 100\n",
    "    \n",
    "    if percent_diff >= 5:\n",
    "        trend = 'Up'\n",
    "    elif percent_diff <= -5:\n",
    "        trend = 'Down'\n",
    "    else:\n",
    "        trend = 'Flat'\n",
    "    \n",
    "    return pd.Series({'Stock_Trend': trend})\n",
    "\n",
    "df_stock_trend = df_stock_data.groupby('Symbol', group_keys=False).apply(label_stock)\n",
    "\n",
    "print(df_stock_trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c74b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_df= stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44306db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating some features to train a random forest\n",
    "monthly_data = stock_data_df.groupby('Symbol').resample('M', on='Date').agg({\n",
    "    'Open': 'first',\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Close': 'last',\n",
    "    'Adj Close': 'last',\n",
    "    'Volume': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_data['Open_Prev_Month'] = monthly_data.groupby('Symbol')['Open'].shift(1)\n",
    "monthly_data['High_Prev_Month'] = monthly_data.groupby('Symbol')['High'].shift(1)\n",
    "monthly_data['Low_Prev_Month'] = monthly_data.groupby('Symbol')['Low'].shift(1)\n",
    "monthly_data['Close_Prev_Month'] = monthly_data.groupby('Symbol')['Close'].shift(1)\n",
    "monthly_data['Volume_Prev_Month'] = monthly_data.groupby('Symbol')['Volume'].shift(1)\n",
    "\n",
    "monthly_data['Volume_Pct_Change_Prev_Month'] = (\n",
    "    (monthly_data['Volume'] / monthly_data['Volume_Prev_Month'] - 1) * 100\n",
    ")\n",
    "\n",
    "#getting the avg open\n",
    "monthly_data['Avg_Open'] = monthly_data.groupby('Symbol')['Open'].rolling(window=2).mean().reset_index(level=0, drop=True)\n",
    "#getting avg close\n",
    "monthly_data['Avg_Close'] = monthly_data.groupby('Symbol')['Close'].rolling(window=2).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "#getting the price range between max and low\n",
    "monthly_data['Price_Range'] = monthly_data['High'] - monthly_data['Low']\n",
    "\n",
    "#getting the price close of one month compared to the other month\n",
    "monthly_data['Price_Momentum'] = monthly_data['Close'] - monthly_data['Close'].shift(1)\n",
    "#getting the vol change between months\n",
    "monthly_data['Volume_Change'] = monthly_data['Volume'] - monthly_data['Volume'].shift(1)\n",
    "#avg vol change\n",
    "monthly_data['Avg_Volume_Change'] = monthly_data['Volume_Change'].rolling(window=2).mean()\n",
    "\n",
    "monthly_data = monthly_data.reset_index(drop=True)\n",
    "\n",
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd54d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = monthly_data.merge(labels_df[['Symbol', 'Date', 'Monthly_Label']], on=['Symbol', 'Date'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496189de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df[['Date','Volume_Pct_Change_Prev_Month',\n",
    "       'Avg_Open', 'Avg_Close', 'Price_Range', 'Price_Momentum',\n",
    "       'Volume_Change', 'Avg_Volume_Change', 'Monthly_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc86729",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sort_values(by='Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f75884",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.set_index('Date',inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45931f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fa5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.Price_Momentum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d173c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(merged_df.Price_Range, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80855f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78337216",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define the encoding based on your domain knowledge\n",
    "class_mapping = {\n",
    "    'Down': 0,\n",
    "    'Up': 1,\n",
    "    'Price Shock': 2,\n",
    "    'Flat': 3\n",
    "}\n",
    "\n",
    "\n",
    "# Map the values using the dictionary (case-insensitive)\n",
    "merged_df['Monthly_Label'] = merged_df['Monthly_Label'].map(class_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ab4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split  # Add this import\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "X = merged_df.loc[:,merged_df.columns != 'Monthly_Label']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "y = merged_df.Monthly_Label\n",
    "\n",
    "cutoff_date = pd.to_datetime('today') - pd.DateOffset(months=6)\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Calculate the date 6 months ago\n",
    "six_months_ago = current_date - timedelta(days=30 * 6)  \n",
    "\n",
    "# Filter X and y data based on the cutoff date\n",
    "X_past = X[X.index < cutoff_date]\n",
    "y_past = y[y.index < cutoff_date]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_future = X[X.index >= six_months_ago]\n",
    "y_future = y[y.index >= six_months_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdfa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5de34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_past, y_past, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b078ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Regularization type (L1 or L2)\n",
    "}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "best_logistic_regression = grid_search.best_estimator_\n",
    "y_pred = best_logistic_regression.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69847cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKES SOME TIME TO RUN\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist, \n",
    "                                   n_iter=50, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "best_rf_classifier = random_search.best_estimator_\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Best Model: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39149ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_future_pred = best_rf_classifier.predict(X_future)\n",
    "accuracy = accuracy_score(y_future, y_future_pred)\n",
    "print(f\"Accuracy with Best Model: {accuracy}\")\n",
    "\n",
    "confusion = confusion_matrix(y_future, y_future_pred)\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "\n",
    "report = classification_report(y_future, y_future_pred)\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "split_date = '2021-01-31'\n",
    "\n",
    "X_train = X_resampled[X_resampled.index < split_date]\n",
    "y_train = y_resampled[y_resampled.index < split_date]\n",
    "X_future = X_resampled[X_resampled.index >= split_date]\n",
    "y_future = y_resampled[y_resampled.index >= split_date]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    predictions = model.predict(X_test_fold)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_fold, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(\"Average Accuracy on Training Data:\", average_accuracy)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, \n",
    "                                   n_iter=50, scoring='accuracy', cv=tscv, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "predictions_future = best_model.predict(X_future)\n",
    "\n",
    "accuracy_future = accuracy_score(y_future, predictions_future)\n",
    "print(\"Accuracy on Future Data:\", accuracy_future)\n",
    "\n",
    "confusion = confusion_matrix(y_future, predictions_future)\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "\n",
    "report = classification_report(y_future, predictions_future)\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'pink'])\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], (y_pred == i).astype(int))\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve (AUC = {roc_auc[i]:.2f}) for Class {i}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beef7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
